{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0, path='checkpoint.pt'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Сколько эпох ждать после последнего улучшения метрики\n",
    "            verbose (bool): Выводить сообщения о каждой проверке (по умолчанию False)\n",
    "            delta (float): Минимальное изменение для улучшения метрики\n",
    "            path (str): Путь для сохранения модели\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Сохранение модели, если валидационная потеря уменьшилась'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "# Пример использования\n",
    "\n",
    "# Инициализация модели, функции потерь и оптимизатора\n",
    "model = ...  # Ваша модель\n",
    "criterion = ...  # Ваша функция потерь\n",
    "optimizer = ...  # Ваш оптимизатор\n",
    "\n",
    "# Параметры ранней остановки\n",
    "early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "\n",
    "# Цикл обучения\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Обучение\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Валидация\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            val_loss += loss.item()\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Validation Loss: {val_loss:.6f}')\n",
    "\n",
    "    # Проверка условия ранней остановки\n",
    "    early_stopping(val_loss, model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "# Загрузка лучших весов модели\n",
    "model.load_state_dict(torch.load('checkpoint.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNLSTM, self).__init__()\n",
    "        self.cnn = models.resnet18(pretrained=True)\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-2])\n",
    "\n",
    "        self.lstm_input_size = self._get_conv_output_size((3, 224, 224))  # Можно использовать произвольный размер\n",
    "        self.lstm = nn.LSTM(self.lstm_input_size, 256, batch_first=True)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def _get_conv_output_size(self, shape):\n",
    "        o = self.cnn(torch.zeros(1, *shape))\n",
    "        return int(torch.prod(torch.tensor(o.size())))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_length, c, h, w = x.size()\n",
    "        x = x.view(batch_size * seq_length, c, h, w)\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(batch_size, seq_length, -1)\n",
    "        x, (h, c) = self.lstm(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x\n",
    "\n",
    "model = CNNLSTM(num_classes=10)\n",
    "\n",
    "# Пример входного тензора с произвольным размером\n",
    "input_tensor = torch.randn(1, 10, 3, 240, 320)  # [batch_size, seq_length, channels, height, width]\n",
    "output = model(input_tensor)\n",
    "print(output.size())  # Ожидаемый размер: [1, 10]\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
